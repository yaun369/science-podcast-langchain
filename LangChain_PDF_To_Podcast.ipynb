{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
    "OPENAI_API_BASE = os.environ['OPENAI_API_BASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('pdf_data/893.pdf')\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# chunk_overlap=0 表示没有重叠的字符\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=0)\n",
    "split_docs = text_splitter.split_documents(pages)\n",
    "print(f'{len(split_docs)} split_docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "persist_directory = \"chroma_storage_893\"\n",
    "\n",
    "if os.path.exists(persist_directory) != True:\n",
    "    # 把分块内容处理成 embeddings\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        split_docs, embeddings, persist_directory=persist_directory)\n",
    "    # 结果持久化\n",
    "    vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '这篇论文和 Transformer 的相关性是什么？'\n",
    "# 加载保存在本地的文档数据\n",
    "vectordb = Chroma(persist_directory=persist_directory,\n",
    "                  embedding_function=embeddings)\n",
    "# 查询与提问最相关的2个文档\n",
    "search_docs = vectordb.similarity_search(query, 2)\n",
    "print(search_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "# 构建llm \n",
    "# temperature=0 意味着需要最保守的回答 减小模型产生幻觉的几率\n",
    "llm = ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY,\n",
    "                 model_name='gpt-3.5-turbo', api_base=OPENAI_API_BASE)\n",
    "chain = load_qa_chain(llm, chain_type='stuff')\n",
    "results = chain.run(input_documents=search_docs, question=query)\n",
    "print(f'Q: {query}')\n",
    "print(f'A: {results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "speak = ET.Element('speak')\n",
    "speak.set('xmlns', 'http://www.w3.org/2001/10/synthesis')\n",
    "speak.set('xmlns:mstts', 'http://www.w3.org/2001/mstts')\n",
    "speak.set('xmlns:emo', 'http://www.w3.org/2009/10/emotionml')\n",
    "speak.set('version', '1.0')\n",
    "speak.set('xml:lang', 'en-US')\n",
    "\n",
    "voice = ET.SubElement(speak, 'voice')\n",
    "voice.set('name', 'zh-TW-YunJheNeural')\n",
    "\n",
    "prosody = ET.SubElement(voice, 'prosody')\n",
    "prosody.set('rate', '20%')\n",
    "prosody.set('pitch', '20%')\n",
    "prosody.text = query + results\n",
    "\n",
    "ET.dump(speak)\n",
    "tree = ET.ElementTree(speak)\n",
    "tree.write(persist_directory + '/SSML.xml', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
